{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eunseochu/OB_2nd/blob/main/%E1%84%86%E1%85%A9%E1%84%83%E1%85%A6%E1%86%AF%E1%84%92%E1%85%AE%E1%86%AB%E1%84%85%E1%85%A7%E1%86%AB_%E1%84%8B%E1%85%A7%E1%86%AB%E1%84%89%E1%85%B3%E1%86%B8%E1%84%86%E1%85%AE%E1%86%AB%E1%84%8C%E1%85%A6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **| ëª¨ë¸ í›ˆë ¨ ì—°ìŠµ ë¬¸ì œ**\n",
        "___\n",
        "- ì¶œì²˜ : í•¸ì¦ˆì˜¨ ë¨¸ì‹ ëŸ¬ë‹ Ch04 ì—°ìŠµë¬¸ì œ 1, 5, 9, 10\n",
        "- ê°œë… ë¬¸ì œì˜ ê²½ìš° í…ìŠ¤íŠ¸ ì…€ì„ ì¶”ê°€í•˜ì—¬ ì •ë‹µì„ ì ì–´ì£¼ì„¸ìš”."
      ],
      "metadata": {
        "id": "zCu72vDHGMHo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. ìˆ˜ë°±ë§Œ ê°œì˜ íŠ¹ì„±ì„ ê°€ì§„ í›ˆë ¨ ì„¸íŠ¸ì—ì„œëŠ” ì–´ë–¤ ì„ í˜• íšŒê·€ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•  ìˆ˜ ìˆì„ê¹Œìš”?**\n",
        "___\n"
      ],
      "metadata": {
        "id": "j3g-_Dq9GiuT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ê²½ì‚¬ í•˜ê°•ë²•ì€ íŠ¹ì„± ìˆ˜ì— ë¯¼ê°í•˜ì§€ ì•Šì•„ ì •ê·œë°©ì •ì‹ì´ë‚˜ SVD ë¶„í•´ë³´ë‹¤ í›¨ì”¬ ë¹ ë¥´ë¯€ë¡œ, <br/>\n",
        "ë°°ì¹˜ ê²½ì‚¬ í•˜ê°•ë²•ì´ë‚˜ í™•ë¥ ì  ê²½ì‚¬ í•˜ê°•ë²•, ë¯¸ë‹ˆë°°ì¹˜ ê²½ì‚¬ í•˜ê°•ë²•ì„ ì´ìš©í•˜ëŠ” ê²ƒì´ ì¢‹ë‹¤"
      ],
      "metadata": {
        "id": "aimE8De97NoP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. ë°°ì¹˜ ê²½ì‚¬ í•˜ê°•ë²•ì„ ì‚¬ìš©í•˜ê³  ì—í¬í¬ë§ˆë‹¤ ê²€ì¦ ì˜¤ì°¨ë¥¼ ê·¸ë˜í”„ë¡œ ë‚˜íƒ€ë‚´ë´¤ìŠµë‹ˆë‹¤. ê²€ì¦ ì˜¤ì°¨ê°€ ì¼ì •í•˜ê²Œ ìƒìŠ¹ë˜ê³  ìˆë‹¤ë©´ ì–´ë–¤ ì¼ì´ ì¼ì–´ë‚˜ê³  ìˆëŠ” ê±¸ê¹Œìš”? ì´ ë¬¸ì œë¥¼ ì–´ë–»ê²Œ í•´ê²°í•  ìˆ˜ ìˆë‚˜ìš”?**\n",
        "___"
      ],
      "metadata": {
        "id": "-pDjW5XcHPOt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ê³¼ëŒ€ ì í•©ì´ ì¼ì–´ë‚¨. ì¡°ê¸° ì¢…ë£Œ ê·œì œë¥¼ í†µí•´ í•´ê²°ê°€ëŠ¥ + í•™ìŠµë¥ "
      ],
      "metadata": {
        "id": "zCZKEd9m74Ms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. ë¦¿ì§€ íšŒê·€ë¥¼ ì‚¬ìš©í–ˆì„ ë•Œ í›ˆë ¨ ì˜¤ì°¨ê°€ ê²€ì¦ ì˜¤ì°¨ê°€ ê±°ì˜ ë¹„ìŠ·í•˜ê³  ë‘˜ ë‹¤ ë†’ì•˜ìŠµë‹ˆë‹¤. ì´ ëª¨ë¸ì—ëŠ” ë†’ì€ í¸í–¥ì´ ë¬¸ì œì¸ê°€ìš”, ì•„ë‹ˆë©´ ë†’ì€ ë¶„ì‚°ì´ ë¬¸ì œì¸ê°€ìš”? ê·œì œ í•˜ì´í¼íŒŒë¼ë¯¸í„° $\\alpha$ë¥¼ ì¦ê°€ì‹œì¼œì•¼ í• ê¹Œìš” ì•„ë‹ˆë©´ ì¤„ì—¬ì•¼ í• ê¹Œìš”?**\n",
        "___"
      ],
      "metadata": {
        "id": "nM7JbsLoy7b7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ê³¼ì†Œì í•©ì´ë©°, ë†’ì€ í¸í–¥ì´ ë¬¸ì œì´ë‹¤. <br/>\n",
        "ğœ¶ë¥¼ ê°ì†Œì‹œì¼œì•¼ í¸í–¥ì´ ì¤„ì–´ë“¤ê³  ë¶„ì‚°ì´ ëŠ˜ì–´ë‚˜ë¯€ë¡œ ì¤„ì—¬ì•¼í•œë‹¤."
      ],
      "metadata": {
        "id": "fn0eYUHy8mSh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. ë‹¤ìŒê³¼ ê°™ì´ ì‚¬ìš©í•´ì•¼ í•˜ëŠ” ì´ìœ ëŠ”?**\n",
        "___\n",
        "- í‰ë²”í•œ ì„ í˜• íšŒê·€(ì¦‰, ì•„ë¬´ëŸ° ê·œì œê°€ ì—†ëŠ” ëª¨ë¸) ëŒ€ì‹  ë¦¿ì§€ íšŒê·€\n",
        "- ë¦¿ì§€ íšŒê·€ ëŒ€ì‹  ë¼ì˜ íšŒê·€\n",
        "- ë¼ì˜ íšŒê·€ ëŒ€ì‹  ì—˜ë¼ìŠ¤í‹±ë„·"
      ],
      "metadata": {
        "id": "C8tARu-ZzOGx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) ì ì–´ë„ ê·œì œê°€ ì•½ê°„ ìˆëŠ” ê²ƒì´ ëŒ€ë¶€ë¶„ì˜ ê²½ìš°ì— ì¢‹ìœ¼ë¯€ë¡œ í‰ë²”í•œ ì„ í˜• íšŒê·€ë³´ë‹¤ëŠ” ë¦¿ì§€ íšŒê·€ë¥¼ ì‚¬ìš©í•´ì•¼ í•¨ <br/>\n",
        "2) ì“°ì´ëŠ” íŠ¹ì„±ì´ ëª‡ ê°œë¿ì´ë¼ê³  ì˜ì‹¬ë˜ë©´, ë¶ˆí•„ìš”í•œ íŠ¹ì„±ì˜ ê°€ì¤‘ì¹˜ë¥¼ 0ìœ¼ë¡œ ë§Œë“¤ì–´ì•¼í•˜ë¯€ë¡œ ë¼ì˜ íšŒê·€ë¥¼ ì‚¬ìš©í•´ì•¼ í•¨ <br/>\n",
        "3) íŠ¹ì„± ìˆ˜ê°€ í›ˆë ¨ ìƒ˜í”Œ ìˆ˜ë³´ë‹¤ ë§ê±°ë‚˜ íŠ¹ì„± ëª‡ ê°œê°€ ê°•í•˜ê²Œ ì—°ê´€ë˜ì–´ ìˆì„ ë•ŒëŠ” ë¼ì˜ì— ë¬¸ì œê°€ ë°œìƒí•˜ë¯€ë¡œ ì—˜ë¼ìŠ¤í‹±ë„·ì„ ì‚¬ìš©í•´ì•¼ í•¨"
      ],
      "metadata": {
        "id": "mpq0cV199ZVU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **5. ì¡°ê¸° ì¢…ë£Œë¥¼ ì‚¬ìš©í•œ ë°°ì¹˜ ê²½ì‚¬ í•˜ê°•ë²•ìœ¼ë¡œ ì†Œí”„íŠ¸ë§¥ìŠ¤ íšŒê·€ë¥¼ êµ¬í˜„í•´ë³´ì„¸ìš”(ì‚¬ì´í‚·ëŸ°ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”)**\n"
      ],
      "metadata": {
        "id": "QIZpOEYJVIAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()\n",
        "\n",
        "X = iris[\"data\"][:, (2, 3)]  # ê½ƒì ê¸¸ì´, ê½ƒì ë„ˆë¹„\n",
        "y = iris[\"target\"]"
      ],
      "metadata": {
        "id": "c_rddeFE98xF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "X_with_bias = np.c_[np.ones([len(X), 1]), X]"
      ],
      "metadata": {
        "id": "WaxlsiXn_1t5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_ratio = 0.2\n",
        "validation_ratio = 0.2\n",
        "total_size = len(X_with_bias)\n",
        "\n",
        "test_size = int(total_size * test_ratio)\n",
        "validation_size = int(total_size * validation_ratio)\n",
        "train_size = total_size - test_size - validation_size\n",
        "\n",
        "rnd_indices = np.random.permutation(total_size)\n",
        "\n",
        "X_train = X_with_bias[rnd_indices[:train_size]]\n",
        "y_train = y[rnd_indices[:train_size]]\n",
        "X_valid = X_with_bias[rnd_indices[train_size:-test_size]]\n",
        "y_valid = y[rnd_indices[train_size:-test_size]]\n",
        "X_test = X_with_bias[rnd_indices[-test_size:]]\n",
        "y_test = y[rnd_indices[-test_size:]]"
      ],
      "metadata": {
        "id": "Ir7jlsZYF17V"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_one_hot(y):\n",
        "    n_classes = y.max() + 1\n",
        "    m = len(y)\n",
        "    Y_one_hot = np.zeros((m, n_classes))\n",
        "    Y_one_hot[np.arange(m), y] = 1\n",
        "    return Y_one_hot"
      ],
      "metadata": {
        "id": "d_TyrRsXF28r"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_one_hot(y_train[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hY2VbKWeF4Nx",
        "outputId": "1f17b809-00a4-4733-db4d-ea5c3082b38c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_train_one_hot = to_one_hot(y_train)\n",
        "Y_valid_one_hot = to_one_hot(y_valid)\n",
        "Y_test_one_hot = to_one_hot(y_test)"
      ],
      "metadata": {
        "id": "8BVTX6J3F9sq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(logits):\n",
        "    exps = np.exp(logits)\n",
        "    exp_sums = np.sum(exps, axis=1, keepdims=True)\n",
        "    return exps / exp_sums"
      ],
      "metadata": {
        "id": "NMzxUtLGF_eP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_inputs = X_train.shape[1] # == 3 (íŠ¹ì„± 2ê°œì™€ í¸í–¥)\n",
        "n_outputs = len(np.unique(y_train))   # == 3 (3ê°œì˜ ë¶“ê½ƒ í´ë˜ìŠ¤)"
      ],
      "metadata": {
        "id": "53Avp23xGA-h"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eta = 0.01\n",
        "n_iterations = 5001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "\n",
        "Theta = np.random.randn(n_inputs, n_outputs)\n",
        "\n",
        "for iteration in range(n_iterations):\n",
        "    logits = X_train.dot(Theta)\n",
        "    Y_proba = softmax(logits)\n",
        "    if iteration % 500 == 0:\n",
        "        loss = -np.mean(np.sum(Y_train_one_hot * np.log(Y_proba + epsilon), axis=1))\n",
        "        print(iteration, loss)\n",
        "    error = Y_proba - Y_train_one_hot\n",
        "    gradients = 1/m * X_train.T.dot(error)\n",
        "    Theta = Theta - eta * gradients"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1g9sq24fGCc-",
        "outputId": "f52665c6-9a10-44b7-a0e3-49c70f5a01ef"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 4.278813646724346\n",
            "500 0.8964942562547653\n",
            "1000 0.7381239835734777\n",
            "1500 0.6418147396986879\n",
            "2000 0.5795726704027496\n",
            "2500 0.536172001007224\n",
            "3000 0.5038220204127604\n",
            "3500 0.4784033812900643\n",
            "4000 0.45760731965423773\n",
            "4500 0.4400602973770405\n",
            "5000 0.4248997333193613\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits = X_valid.dot(Theta)\n",
        "Y_proba = softmax(logits)\n",
        "y_predict = np.argmax(Y_proba, axis=1)\n",
        "\n",
        "accuracy_score = np.mean(y_predict == y_valid)\n",
        "accuracy_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fa0epFxfGD7u",
        "outputId": "9d50dc11-f038-453b-ed50-2e2fbf159992"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eta = 0.1\n",
        "n_iterations = 5001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "alpha = 0.1  # ê·œì œ í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
        "\n",
        "Theta = np.random.randn(n_inputs, n_outputs)\n",
        "\n",
        "for iteration in range(n_iterations):\n",
        "    logits = X_train.dot(Theta)\n",
        "    Y_proba = softmax(logits)\n",
        "    if iteration % 500 == 0:\n",
        "        xentropy_loss = -np.mean(np.sum(Y_train_one_hot * np.log(Y_proba + epsilon), axis=1))\n",
        "        l2_loss = 1/2 * np.sum(np.square(Theta[1:]))\n",
        "        loss = xentropy_loss + alpha * l2_loss\n",
        "        print(iteration, loss)\n",
        "    error = Y_proba - Y_train_one_hot\n",
        "    gradients = 1/m * X_train.T.dot(error) + np.r_[np.zeros([1, n_outputs]), alpha * Theta[1:]]\n",
        "    Theta = Theta - eta * gradients"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHONEhpHGF2i",
        "outputId": "5c5599b7-f67e-4627-93b3-09a54debd9a3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 5.2985884587953755\n",
            "500 0.5525172953098062\n",
            "1000 0.5244678245758908\n",
            "1500 0.5159742835914052\n",
            "2000 0.5127530965510835\n",
            "2500 0.5114313541945427\n",
            "3000 0.5108669424481664\n",
            "3500 0.5106203104997997\n",
            "4000 0.5105110043223846\n",
            "4500 0.510462123049836\n",
            "5000 0.510440135739566\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits = X_valid.dot(Theta)\n",
        "Y_proba = softmax(logits)\n",
        "y_predict = np.argmax(Y_proba, axis=1)\n",
        "\n",
        "accuracy_score = np.mean(y_predict == y_valid)\n",
        "accuracy_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5jsFUtIGHQN",
        "outputId": "985876f2-e0c1-4161-9301-27edb14fa756"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eta = 0.1 \n",
        "n_iterations = 5001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "alpha = 0.1  # ê·œì œ í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
        "best_loss = np.infty\n",
        "\n",
        "Theta = np.random.randn(n_inputs, n_outputs)\n",
        "\n",
        "for iteration in range(n_iterations):\n",
        "    logits = X_train.dot(Theta)\n",
        "    Y_proba = softmax(logits)\n",
        "    error = Y_proba - Y_train_one_hot\n",
        "    gradients = 1/m * X_train.T.dot(error) + np.r_[np.zeros([1, n_outputs]), alpha * Theta[1:]]\n",
        "    Theta = Theta - eta * gradients\n",
        "\n",
        "    logits = X_valid.dot(Theta)\n",
        "    Y_proba = softmax(logits)\n",
        "    xentropy_loss = -np.mean(np.sum(Y_valid_one_hot * np.log(Y_proba + epsilon), axis=1))\n",
        "    l2_loss = 1/2 * np.sum(np.square(Theta[1:]))\n",
        "    loss = xentropy_loss + alpha * l2_loss\n",
        "    if iteration % 500 == 0:\n",
        "        print(iteration, loss)\n",
        "    if loss < best_loss:\n",
        "        best_loss = loss\n",
        "    else:\n",
        "        print(iteration - 1, best_loss)\n",
        "        print(iteration, loss, \"ì¡°ê¸° ì¢…ë£Œ!\")\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUsOn6rcGJFZ",
        "outputId": "031dcf48-27ae-4b94-abc4-c36ccc73a670"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1.853771505437449\n",
            "500 0.5625127586244476\n",
            "1000 0.5347683195598181\n",
            "1500 0.5269703098990515\n",
            "2000 0.5243492084519632\n",
            "2500 0.523466284043304\n",
            "3000 0.5232087092206062\n",
            "3403 0.5231716332437188\n",
            "3404 0.5231716332767864 ì¡°ê¸° ì¢…ë£Œ!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits = X_valid.dot(Theta)\n",
        "Y_proba = softmax(logits)\n",
        "y_predict = np.argmax(Y_proba, axis=1)\n",
        "\n",
        "accuracy_score = np.mean(y_predict == y_valid)\n",
        "accuracy_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M25_rW8nGKx_",
        "outputId": "7ce70a79-0994-4841-a62b-6119bafd0c3a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits = X_test.dot(Theta)\n",
        "Y_proba = softmax(logits)\n",
        "y_predict = np.argmax(Y_proba, axis=1)\n",
        "\n",
        "accuracy_score = np.mean(y_predict == y_test)\n",
        "accuracy_score\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAqmND7fGL9L",
        "outputId": "9beb9266-2f24-408b-e48a-38fccad95a28"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666666666666667"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sSL8fNvTGNUB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}